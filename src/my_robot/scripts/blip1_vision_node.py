#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import torch
from transformers import BlipForConditionalGeneration, BlipProcessor
from PIL import Image as PILImage
import cv2
import numpy as np

class BLIPVisionNode(Node):
    def __init__(self):
        super().__init__('blip_vision_node')
        
        self.get_logger().info("ğŸš€ BLIP Vision Node Starting...")
        
        # GPU ì„¤ì •
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info(f"ğŸ“± Using device: {self.device}")
        
        # BLIP ëª¨ë¸ ë¡œë“œ
        self.get_logger().info("ğŸ“¦ Loading BLIP model...")
        model_name = "Salesforce/blip-image-captioning-large"
        
        self.processor = BlipProcessor.from_pretrained(model_name)
        self.model = BlipForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device.type == 'cuda' else torch.float32
        ).to(self.device)
        
        self.get_logger().info("âœ… Model loaded successfully!")
        
        # CV Bridge (ROS Image â†” OpenCV)
        self.bridge = CvBridge()
        
        # ì¹´ë©”ë¼ êµ¬ë…
        self.subscription = self.create_subscription(
            Image,
            '/camera_left/image_raw',  # í† í”½ ì´ë¦„
            self.image_callback,
            10
        )
        
        # ìµœì‹  í”„ë ˆì„ ì €ì¥
        self.latest_frame = None
        self.frame_count = 0
        
        # 1ì´ˆë§ˆë‹¤ ì²˜ë¦¬ (í”„ë ˆì„ ì œì–´)
        self.timer = self.create_timer(1.0, self.process_frame)
        
        # ìì—°ì–´ ëª…ë ¹ (ë‚˜ì¤‘ì— í† í”½ìœ¼ë¡œ ë°›ì„ ìˆ˜ë„ ìˆìŒ)
        self.question = "What objects are in this image?"
        
        self.get_logger().info("ğŸ¥ Subscribed to /camera_left/image_raw")
        self.get_logger().info(f"â“ Question: {self.question}")
    
    def image_callback(self, msg):
        """ì¹´ë©”ë¼ ì´ë¯¸ì§€ ìˆ˜ì‹  (ë§¤ í”„ë ˆì„)"""
        try:
            # ROS Image â†’ OpenCV
            cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
            self.latest_frame = cv_image
            self.frame_count += 1
        except Exception as e:
            self.get_logger().error(f"Image conversion error: {e}")
    
    def process_frame(self):
        """1ì´ˆë§ˆë‹¤ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        if self.latest_frame is None:
            self.get_logger().warn("â³ Waiting for camera image...")
            return
        
        self.get_logger().info(f"ğŸ–¼ï¸  Processing frame #{self.frame_count}")
        
        try:
            # OpenCV (BGR) â†’ PIL (RGB)
            rgb_image = cv2.cvtColor(self.latest_frame, cv2.COLOR_BGR2RGB)
            pil_image = PILImage.fromarray(rgb_image)
            
            # BLIP ì…ë ¥ ì¤€ë¹„
            inputs = self.processor(images=pil_image, text=self.question, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì¶”ë¡ 
            with torch.no_grad():
                generated_ids = self.model.generate(**inputs, max_new_tokens=50)
            
            # ê²°ê³¼ ë””ì½”ë”©
            answer = self.processor.decode(generated_ids[0], skip_special_tokens=True)
            
            # ê²°ê³¼ ì¶œë ¥
            self.get_logger().info(f"â“ Q: {self.question}")
            self.get_logger().info(f"âœ… A: {answer}")
            self.get_logger().info("â”€" * 50)
            
            # ì‹œê°í™” (ì„ íƒì‚¬í•­)
            self.visualize_result(self.latest_frame, answer)
            
        except Exception as e:
            self.get_logger().error(f"âŒ Processing error: {e}")
    
    def visualize_result(self, image, text):
        """ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— í‘œì‹œ"""
        display_img = image.copy()
        
        # í…ìŠ¤íŠ¸ ë°°ê²½
        cv2.rectangle(display_img, (10, 10), (700, 80), (0, 0, 0), -1)
        
        # í…ìŠ¤íŠ¸ (ë‹µë³€)
        cv2.putText(
            display_img,
            f"Answer: {text}",
            (20, 50),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (0, 255, 0),
            2
        )
        
        # í™”ë©´ í‘œì‹œ
        cv2.imshow('BLIP Vision', display_img)
        cv2.waitKey(1)


def main(args=None):
    rclpy.init(args=args)
    
    try:
        node = BLIPVisionNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyAllWindows()
        rclpy.shutdown()


if __name__ == '__main__':
    main()