#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

import threading
import sys
import time

import torch
from transformers import BlipProcessor, BlipForQuestionAnswering
from PIL import Image as PILImage
import cv2

# Ultralytics YOLOv8
from ultralytics import YOLO


class BLIPYOLONode(Node):
    def __init__(self):
        super().__init__('blip_yolo_node')
        self.get_logger().info("ğŸš€ BLIP + YOLO node starting...")

        # ---------- Device ----------
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info(f"ğŸ“± Using device: {self.device}")

        # ---------- BLIP (VQA) ----------
        self.get_logger().info("ğŸ“¦ Loading BLIP-VQA...")
        self.vqa_model_name = "Salesforce/blip-vqa-base"
        self.blip_processor = BlipProcessor.from_pretrained(self.vqa_model_name)
        self.blip_model = BlipForQuestionAnswering.from_pretrained(
            self.vqa_model_name,
            torch_dtype=torch.float16 if self.device.type == 'cuda' else torch.float32
        ).to(self.device)
        self.get_logger().info("âœ… BLIP ready")

        # ---------- YOLO ----------
        self.get_logger().info("ğŸ“¦ Loading YOLOv8 (n)...")
        self.yolo = YOLO("yolov8n.pt")  # ê°€ë²¼ìš´ ê¸°ë³¸ ëª¨ë¸
        # ê²°ê³¼ë¬¼ ìë™ ì €ì¥ ë°©ì§€
        try:
            self.yolo.overrides['save'] = False
        except Exception:
            pass
        self.get_logger().info("âœ… YOLO ready")

        # ---------- ROS image subscription ----------
        self.bridge = CvBridge()
        self.latest_frame = None
        self.frame_count = 0

        self.subscription = self.create_subscription(
            Image, '/camera_left/image_raw', self.image_callback, 10
        )
        # ì²« í”„ë ˆì„ì´ ì˜¤ê¸° ì „ì— ì…ë ¥ í”„ë¡¬í”„íŠ¸ê°€ ë¨¼ì € ì¶œë ¥ë˜ë„ë¡ ì•½ê°„ì˜ ì§€ì—°
        self.get_logger().info("ğŸ¥ Subscribed to /camera_left/image_raw")
        sys.stdout.flush()
        time.sleep(0.2)

        # ---------- UI / State ----------
        self.running = True
        self.last_answer_text = ""
        self.win_name = "BLIP + YOLO"

        # ì…ë ¥ ìŠ¤ë ˆë“œ ì‹œì‘
        self.input_thread = threading.Thread(target=self._input_loop, daemon=True)
        self.input_thread.start()

        # ì£¼ê¸°ì ì¸ í™”ë©´ ê°±ì‹ (í”„ë¡¬í”„íŠ¸ ëŒ€ê¸° ì¤‘ì—ë„ í™”ë©´ ìœ ì§€)
        self.timer = self.create_timer(0.2, self._refresh_window)

    # -------------------- ROS callbacks --------------------
    def image_callback(self, msg: Image):
        try:
            # encodingì´ rgb8ì´ë©´ BGRë¡œ ë°”ê¿”ì•¼ OpenCV í‘œì¤€ ì‹œê°í™”ì™€ ì¼ì¹˜
            if msg.encoding.lower().startswith('rgb'):
                cv_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')
                cv_img = cv2.cvtColor(cv_img, cv2.COLOR_RGB2BGR)
            else:
                cv_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')

            self.latest_frame = cv_img
            self.frame_count += 1
        except Exception as e:
            self.get_logger().error(f"Image conversion error: {e}")

    # -------------------- Input / Inference --------------------
    def _input_loop(self):
        """í„°ë¯¸ë„ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥ë°›ê³ , í•œ ë²ˆ ì¶”ë¡ ì„ ìˆ˜í–‰í•œë‹¤."""
        while self.running:
            try:
                q = input("\nğŸ’¬ ì§ˆë¬¸ ì…ë ¥ (ì˜ˆ: Is there a chair? / ì¢…ë£Œ: exit): ").strip()
                if q.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
                    self.get_logger().info("ğŸ›‘ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    self.safe_shutdown()
                    return

                if self.latest_frame is None:
                    print("âš ï¸ ì•„ì§ ì¹´ë©”ë¼ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                    continue

                # 1) BLIP VQA
                blip_answer = self.run_blip_vqa(self.latest_frame, q)

                # 2) YOLO detection
                detections = self.run_yolo(self.latest_frame)

                # 3) ë§¤ì¹­(ì„ íƒ): ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°„ë‹¨ ë§¤ì¹­ ì‹œë„
                matched = self.simple_match(q, detections)

                # 4) ì‹œê°í™” í…ìŠ¤íŠ¸ êµ¬ì„±
                if len(detections) == 0:
                    det_text = "âŒ No object detected in image"
                else:
                    det_text = "âœ… Detected: " + ", ".join(
                        [f"{d['class']}({d['confidence']:.2f})" for d in detections]
                    )

                self.last_answer_text = (
                    f"Q: {q}\n"
                    f"ğŸ’­ BLIP Answer: {blip_answer}\n"
                    f"{det_text}\n"
                    f"{'ğŸ¯ Matched!' if matched else ''}"
                )

                # í•œ ë²ˆ ê·¸ë ¤ì£¼ê¸°
                self.visualize(self.latest_frame, q, blip_answer, detections)

            except EOFError:
                self.safe_shutdown()
                return
            except KeyboardInterrupt:
                self.safe_shutdown()
                return

    # -------------------- Models --------------------
    def run_blip_vqa(self, bgr_image, question: str) -> str:
        # BGR -> RGB -> PIL
        rgb = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)
        pil_img = PILImage.fromarray(rgb)

        inputs = self.blip_processor(images=pil_img, text=question, return_tensors="pt").to(self.device)
        with torch.no_grad():
            output_ids = self.blip_model.generate(**inputs, max_new_tokens=40)
        answer = self.blip_processor.decode(output_ids[0], skip_special_tokens=True)
        self.get_logger().info(f"? Question: {question}")
        self.get_logger().info(f"ğŸ’¬ BLIP Answer: {answer}")
        return answer

    def run_yolo(self, bgr_image):
        """Ultralytics ìµœì‹  API ë°©ì‹ìœ¼ë¡œ ë°•ìŠ¤ íŒŒì‹±."""
        results = self.yolo(bgr_image, verbose=False)[0]
        detections = []
        try:
            for box in results.boxes:
                cls_id = int(box.cls[0])
                cls_name = results.names[cls_id] if hasattr(results, 'names') else str(cls_id)
                conf = float(box.conf[0])
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().tolist()
                cx, cy = (x1 + x2) / 2, (y1 + y2) / 2
                detections.append({
                    "class": cls_name,
                    "confidence": conf,
                    "bbox": (x1, y1, x2, y2),
                    "center": (cx, cy),
                })
        except Exception as e:
            self.get_logger().warn(f"YOLO parsing warning: {e}")
        return detections

    # ê°„ë‹¨ ë§¤ì¹­(ì§ˆë¬¸ì— ë“±ì¥í•˜ëŠ” ë‹¨ì–´ê°€ íƒì§€ í´ë˜ìŠ¤ì— í¬í•¨ë˜ë©´ ë§¤ì¹˜ë¡œ ê°„ì£¼)
    def simple_match(self, question: str, detections) -> bool:
        q = question.lower()
        for det in detections:
            if det["class"].lower() in q:
                return True
        return False

    # -------------------- Visualization --------------------
    def visualize(self, frame_bgr, question: str, blip_answer: str, detections):
        img = frame_bgr.copy()

        # ìƒë‹¨ í…ìŠ¤íŠ¸ ë°•ìŠ¤
        top_h = 90
        cv2.rectangle(img, (10, 10), (10 + 800, 10 + top_h), (0, 0, 0), -1)
        cv2.putText(img, f"Q: {question}", (20, 45),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2)
        cv2.putText(img, f"A: {blip_answer}", (20, 80),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)

        # YOLO ë°•ìŠ¤
        for det in detections:
            x1, y1, x2, y2 = map(int, det["bbox"])
            label = f"{det['class']} {det['confidence']:.2f}"
            cv2.rectangle(img, (x1, y1), (x2, y2), (50, 200, 255), 2)
            cv2.circle(img, (int(det["center"][0]), int(det["center"][1])), 4, (0, 255, 0), -1)
            cv2.putText(img, label, (x1, max(20, y1 - 8)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 200, 255), 2)

        cv2.imshow(self.win_name, img)
        # 'q'ë¡œ ì¢…ë£Œ
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            self.get_logger().info("ğŸ›‘ 'q' pressed. Shutting down.")
            self.safe_shutdown()

    def _refresh_window(self):
        """í”„ë ˆì„ì´ ë“¤ì–´ì˜¤ë©´ ë§ˆì§€ë§‰ ë‹µë³€ í…ìŠ¤íŠ¸ë¼ë„ ë„ì›Œ ì‚¬ìš©ìê°€ ìƒíƒœë¥¼ ë³¼ ìˆ˜ ìˆê²Œ í•¨."""
        if self.latest_frame is None:
            return
        # ìµœê·¼ ì •ë³´ê°€ ìˆìœ¼ë©´ ê°„ë‹¨íˆ ìƒë‹¨ë§Œ í‘œì‹œí•´ ìœ ì§€
        img = self.latest_frame.copy()
        if self.last_answer_text:
            block_w, block_h = 900, 110
            cv2.rectangle(img, (10, 10), (10 + block_w, 10 + block_h), (0, 0, 0), -1)
            for i, line in enumerate(self.last_answer_text.split("\n")[:3]):
                cv2.putText(img, line, (20, 45 + i * 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0) if i == 1 else (255, 255, 255), 2)
        cv2.imshow(self.win_name, img)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            self.safe_shutdown()

    # -------------------- Shutdown --------------------
    def safe_shutdown(self):
        if not self.running:
            return
        self.running = False
        try:
            cv2.destroyAllWindows()
        except Exception:
            pass
        try:
            if rclpy.ok():
                rclpy.shutdown()
        except Exception:
            pass
        # ì…ë ¥ ìŠ¤ë ˆë“œê°€ ì‚´ì•„ìˆë‹¤ë©´ ì¢…ë£Œ ìœ ë„
        try:
            sys.stdout.flush()
        except Exception:
            pass
        # í”„ë¡œì„¸ìŠ¤ ì¢…ë£ŒëŠ” ë©”ì¸ì—ì„œ ë§¡ê¹€


def main(args=None):
    rclpy.init(args=args)
    node = BLIPYOLONode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.safe_shutdown()
    finally:
        # ì¤‘ë³µ ì¢…ë£Œ ë°©ì§€
        if rclpy.ok():
            rclpy.shutdown()
        try:
            cv2.destroyAllWindows()
        except Exception:
            pass


if __name__ == "__main__":
    main()
