#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import torch
from transformers import BlipProcessor, BlipForConditionalGeneration, BlipForQuestionAnswering
from PIL import Image as PILImage
import cv2
import threading
import sys
import time


class BLIPHybridNode(Node):
    def __init__(self):
        super().__init__('blip_hybrid_node')
        self.get_logger().info("ğŸš€ BLIP Hybrid Node Starting (Caption + VQA)...")

        # âœ… GPU ì„¤ì •
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info(f"ğŸ“± Using device: {self.device}")

        # âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        self.caption_model_name = "Salesforce/blip-image-captioning-large"
        self.vqa_model_name = "Salesforce/blip-vqa-base"

        self.caption_processor = BlipProcessor.from_pretrained(self.caption_model_name)
        self.caption_model = BlipForConditionalGeneration.from_pretrained(
            self.caption_model_name,
            torch_dtype=torch.float16 if self.device.type == 'cuda' else torch.float32
        ).to(self.device)

        self.vqa_processor = BlipProcessor.from_pretrained(self.vqa_model_name)
        self.vqa_model = BlipForQuestionAnswering.from_pretrained(
            self.vqa_model_name,
            torch_dtype=torch.float16 if self.device.type == 'cuda' else torch.float32
        ).to(self.device)

        self.get_logger().info("âœ… Both models loaded successfully!")

        # âœ… ROS ì´ë¯¸ì§€ êµ¬ë…
        self.bridge = CvBridge()
        self.subscription = self.create_subscription(
            Image, '/camera_left/image_raw', self.image_callback, 10
        )

        self.latest_frame = None
        self.frame_count = 0
        self.running = True

        # ğŸ¥ Subscribed ë¡œê·¸ â†’ flush ì²˜ë¦¬ (ì¶œë ¥ ìˆœì„œ ë³´ì •)
        self.get_logger().info("ğŸ¥ Subscribed to /camera_left/image_raw")
        sys.stdout.flush()
        time.sleep(0.2)

        # âœ… ì‚¬ìš©ì ì…ë ¥ ìŠ¤ë ˆë“œ ì‹œì‘
        self.user_input_thread = threading.Thread(target=self._input_loop, daemon=True)
        self.user_input_thread.start()

    def image_callback(self, msg):
        try:
            self.latest_frame = self.bridge.imgmsg_to_cv2(msg, 'bgr8')
            self.frame_count += 1
        except Exception as e:
            self.get_logger().error(f"Image conversion error: {e}")

    def _input_loop(self):
        """ğŸ’¬ ì…ë ¥ ê¸°ë°˜ ì¶”ë¡  (íƒ€ì´ë¨¸ ì—†ì´, ì…ë ¥ ì‹œë§Œ ì‹¤í–‰)"""
        while self.running:
            try:
                question = input("\nğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: Is there a red apple? / ì¢…ë£Œ: exit): ").strip()
                sys.stdout.flush()

                if question.lower() in ["exit", "quit", "ì¢…ë£Œ"]:
                    self.get_logger().info("ğŸ›‘ ì¢…ë£Œ ëª…ë ¹ ê°ì§€ â€” í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    self.running = False
                    cv2.destroyAllWindows()
                    try:
                        rclpy.try_shutdown()  # ì¤‘ë³µ shutdown ë°©ì§€
                    except Exception:
                        pass
                    sys.exit(0)

                if self.latest_frame is None:
                    print("âš ï¸ ì•„ì§ ì¹´ë©”ë¼ í”„ë ˆì„ì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                    continue

                rgb_image = cv2.cvtColor(self.latest_frame, cv2.COLOR_BGR2RGB)
                pil_image = PILImage.fromarray(rgb_image)

                # ë¬¼ìŒí˜•ì´ë©´ VQA, ì•„ë‹ˆë©´ Caption
                if self.is_question_type(question):
                    answer = self.run_vqa(pil_image, question)
                else:
                    answer = self.run_captioning(pil_image)

                self.visualize_result(self.latest_frame, f"{answer}")

            except EOFError:
                break
            except KeyboardInterrupt:
                self.clean_exit()

    def clean_exit(self):
        """ğŸ§¹ ì¢…ë£Œ ì²˜ë¦¬"""
        self.get_logger().info("ğŸ§¹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        self.running = False
        cv2.destroyAllWindows()
        try:
            rclpy.try_shutdown()
        except Exception:
            pass
        sys.exit(0)

    def is_question_type(self, text):
        """ë¬¸ì¥ì´ ë¬¼ìŒí˜•ì¸ì§€ íŒë‹¨"""
        keywords = ["?", "ìˆ", "where", "what", "is there", "are there", "who"]
        return any(k in text.lower() for k in keywords)

    def run_vqa(self, pil_image, question):
        """BLIP VQA ì‹¤í–‰"""
        self.get_logger().info(f"ğŸ§  [VQA] Q: {question}")
        inputs = self.vqa_processor(images=pil_image, text=question, return_tensors="pt").to(self.device)
        with torch.no_grad():
            output = self.vqa_model.generate(**inputs, max_new_tokens=50)
        answer = self.vqa_processor.decode(output[0], skip_special_tokens=True)
        self.get_logger().info(f"âœ… A: {answer}")
        return f"Q: {question} | A: {answer}"

    def run_captioning(self, pil_image):
        """BLIP Captioning ì‹¤í–‰"""
        self.get_logger().info("ğŸ–¼ï¸ [Captioning] Generating scene description...")
        inputs = self.caption_processor(images=pil_image, return_tensors="pt").to(self.device)
        with torch.no_grad():
            output = self.caption_model.generate(**inputs, max_new_tokens=50)
        caption = self.caption_processor.decode(output[0], skip_special_tokens=True)
        self.get_logger().info(f"ğŸ“ Caption: {caption}")
        return caption

    def visualize_result(self, image, text):
        """ê²°ê³¼ ì‹œê°í™”"""
        display_img = image.copy()
        cv2.rectangle(display_img, (10, 10), (850, 80), (0, 0, 0), -1)
        cv2.putText(display_img, text[:100], (20, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.imshow('BLIP Hybrid Output', display_img)

        # ğŸ”¹ q í‚¤ë¡œ ì¢…ë£Œ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            self.clean_exit()


def main(args=None):
    rclpy.init(args=args)
    try:
        node = BLIPHybridNode()
        rclpy.spin(node)
    except KeyboardInterrupt:
        node.clean_exit()
    finally:
        cv2.destroyAllWindows()
        try:
            rclpy.try_shutdown()
        except Exception:
            pass


if __name__ == '__main__':
    main()
